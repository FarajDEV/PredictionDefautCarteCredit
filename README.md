<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/c/ca/LinkedIn_logo_initials.png" height="128">
  <h2 align="center"><a href="https://www.linkedin.com/in/cheniki-faraj-%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB-575a352b7/">LinkedIn</a></h2>
</p>

<br>

![](https://i.imgur.com/waxVImv.png)

# PrÃ©diction de DÃ©faut de Carte de CrÃ©dit avec AWS SageMaker Studio ğŸš€

## Projet NÂ°3 ğŸ”„ ğŸ”
#  ğŸ›ï¸âœ¨PredictionDefautCarteCreditâœ¨ğŸ›ï¸

Bienvenue dans notre projet de **PrÃ©diction de DÃ©faut de Carte de CrÃ©dit**. 
Ce projet utilise AWS SageMaker Studio pour dÃ©velopper, entraÃ®ner et dÃ©ployer un modÃ¨le de machine learning capable de prÃ©dire les dÃ©fauts de paiement des clients de cartes de crÃ©dit. ğŸŒŸ

## Table des MatiÃ¨res
- [Description ğŸ“–](#description-)
- [Cahier des Charges ğŸ“‹](#cahier-des-charges-)
- [FonctionnalitÃ©s âœ¨](#fonctionnalitÃ©s-)
- [Structure du Projet ğŸ—ï¸](#structure-du-projet-)
- [RÃ©alisation ğŸ› ï¸](#rÃ©alisation-)
- [Structure du Code ğŸ§©](#structure-du-code-)
- [DifficultÃ©s RencontrÃ©es ğŸš§](#difficultÃ©s-rencontrÃ©es-)
- [AmÃ©liorations Futures ğŸ”®](#amÃ©liorations-futures-)
- [Frameworks et Technologies UtilisÃ©s ğŸ› ï¸](#frameworks-et-technologies-utilisÃ©s-)
- [Auteurs et Contributions âœ¨](#auteurs-et-contributions-)
- [RÃ©fÃ©rences et Ressources ğŸ“š](#rÃ©fÃ©rences-et-ressources-)

## Description ğŸ“–

### Contexte
Dans le secteur bancaire, l'Ã©valuation du risque de crÃ©dit est essentielle pour rÃ©duire les pertes financiÃ¨res dues aux dÃ©fauts de paiement. Les modÃ¨les de machine learning peuvent grandement amÃ©liorer la prÃ©cision de ces Ã©valuations en analysant des donnÃ©es complexes et volumineuses.

### Objectif
Le but de ce projet est de dÃ©velopper un modÃ¨le de machine learning utilisant **XGBoost** pour prÃ©dire la probabilitÃ© qu'un client de carte de crÃ©dit ne puisse pas honorer ses paiements. Nous utilisons AWS SageMaker Studio pour l'entraÃ®nement, l'optimisation et le dÃ©ploiement de notre modÃ¨le.

## Cahier des Charges ğŸ“‹

### Besoins Fonctionnels
- **PrÃ©-traitement des donnÃ©es** pour amÃ©liorer la qualitÃ© des entrÃ©es du modÃ¨le.
- **EntraÃ®nement et optimisation** d'un modÃ¨le de machine learning performant.
- **DÃ©ploiement du modÃ¨le** sur AWS SageMaker pour une utilisation en production.
- **Ã‰valuation continue** des performances du modÃ¨le et ajustements si nÃ©cessaire.

### Contraintes Techniques
- Utilisation de **AWS SageMaker Studio** pour le dÃ©veloppement, l'entraÃ®nement et le dÃ©ploiement.
- ModÃ¨le capable de traiter des donnÃ©es volumineuses et variÃ©es.

## FonctionnalitÃ©s âœ¨

- **PrÃ©paration des DonnÃ©es** : Nettoyage, transformation et normalisation des donnÃ©es de carte de crÃ©dit. (Voir le tableau joint, c'est dÃ©jÃ  fait!)
- **EntraÃ®nement du ModÃ¨le** : Utilisation de XGBoost pour entraÃ®ner un modÃ¨le de classification.
- **Optimisation des HyperparamÃ¨tres** : Recherche des meilleurs paramÃ¨tres pour amÃ©liorer les performances du modÃ¨le.
- **DÃ©ploiement** : HÃ©bergement du modÃ¨le sur un endpoint SageMaker pour l'infÃ©rence en temps rÃ©el.
- **Ã‰valuation** : Analyse des performances du modÃ¨le sur des jeux de donnÃ©es de test.

## Structure du Projet ğŸ—ï¸

### Architecture
Le projet est structurÃ© en plusieurs Ã©tapes :
1. **PrÃ©paration des DonnÃ©es** : Nettoyage, transformation et normalisation des donnÃ©es de carte de crÃ©dit.
2. **EntraÃ®nement du ModÃ¨le** : Utilisation de XGBoost pour entraÃ®ner un modÃ¨le de classification.
3. **Optimisation des HyperparamÃ¨tres** : Recherche des meilleurs paramÃ¨tres pour amÃ©liorer les performances du modÃ¨le.
4. **DÃ©ploiement** : HÃ©bergement du modÃ¨le sur un endpoint SageMaker pour l'infÃ©rence en temps rÃ©el.
5. **Ã‰valuation** : Analyse des performances du modÃ¨le sur des jeux de donnÃ©es de test.

## RÃ©alisation ğŸ› ï¸

### PrÃ©paration des DonnÃ©es
- **Nettoyage des donnÃ©es** pour Ã©liminer les valeurs manquantes et les anomalies.
- **Transformation des variables** pour standardiser les entrÃ©es.
- **Normalisation** pour assurer une Ã©chelle uniforme des caractÃ©ristiques.

### EntraÃ®nement et Optimisation
- **SÃ©paration des donnÃ©es** en ensembles d'entraÃ®nement et de test.
- **EntraÃ®nement initial** du modÃ¨le sur l'ensemble d'entraÃ®nement.
- **Optimisation des hyperparamÃ¨tres** Ã  l'aide de techniques comme la recherche en grille.

### DÃ©ploiement
- **CrÃ©ation d'un endpoint** SageMaker pour hÃ©berger le modÃ¨le.
- **Configuration de l'infÃ©rence en temps rÃ©el** pour prÃ©dire les dÃ©fauts de paiement.

### Ã‰valuation
- **PrÃ©cision** : 81.5%
- **Rappel** : 68%
- **Graphiques des performances** : PrÃ©sentation des mÃ©triques de performance sous forme graphique.
- **Importance des caractÃ©ristiques** : Analyse des variables les plus influentes.

## Structure du Code ğŸ§©
Dans le fichier DÃ©tection_localisation_tumeurs.py, comme suit:
â”‚ â”œâ”€â”€ data_cleaning.py
â”‚ â”œâ”€â”€ data_transformation.py
â”‚ â””â”€â”€ data_normalization.py
â”œâ”€â”€ model_training
â”‚ â”œâ”€â”€ train_model.py
â”‚ â””â”€â”€ optimize_hyperparameters.py
â”œâ”€â”€ deployment
â”‚ â”œâ”€â”€ deploy_model.py
â”‚ â””â”€â”€ inference.py
â”œâ”€â”€ evaluation
â”‚ â”œâ”€â”€ evaluate_model.py
â”‚ â””â”€â”€ performance_metrics.py


## DifficultÃ©s RencontrÃ©es ğŸš§

- **PrÃ©-traitement des donnÃ©es** : Gestion des valeurs manquantes et des anomalies dans les donnÃ©es.
- **Optimisation des hyperparamÃ¨tres** : Trouver les meilleurs paramÃ¨tres pour maximiser la performance du modÃ¨le.
- **DÃ©ploiement** : Configuration et gestion du endpoint SageMaker pour l'infÃ©rence en temps rÃ©el.

## AmÃ©liorations Futures ğŸ”®

- **AmÃ©lioration du modÃ¨le** : IntÃ©grer des donnÃ©es supplÃ©mentaires et tester d'autres algorithmes.
- **DÃ©ploiement Ã  grande Ã©chelle** : IntÃ©gration dans des systÃ¨mes de gestion de risques bancaires.
- **Surveillance et mise Ã  jour** : Mettre en place des mÃ©canismes pour surveiller et mettre Ã  jour rÃ©guliÃ¨rement le modÃ¨le.
- **Automatisation** : Automatiser le pipeline de dÃ©ploiement pour rÃ©duire les interventions manuelles.

## Frameworks et Technologies UtilisÃ©s ğŸ› ï¸

- **AWS SageMaker Studio** : Plateforme pour le dÃ©veloppement, l'entraÃ®nement et le dÃ©ploiement de modÃ¨les de machine learning.
- **XGBoost** : Algorithme de gradient boosting performant pour les tÃ¢ches de classification.
- **Pandas** : BibliothÃ¨que pour la manipulation et l'analyse des donnÃ©es.
- **Scikit-learn** : BibliothÃ¨que pour les tÃ¢ches de machine learning et d'Ã©valuation de modÃ¨les.
- **NumPy** : BibliothÃ¨que pour les opÃ©rations mathÃ©matiques et les manipulations de tableaux.

## Auteurs et Contributions âœ¨

Nous remercions tous ceux qui ont contribuÃ© Ã  ce projet sur GitHub et qui m'ont aidÃ© Ã  rÃ©soudre plusieurs problÃ¨mes que j'ai fait face.

## RÃ©fÃ©rences et Ressources ğŸ“š

- [Documentation Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/)
- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)

---

![](https://i.imgur.com/waxVImv.png)


#MachineLearning #CreditRisk #DataScience #AWS #SageMaker #XGBoost #BigData #AI #ArtificialIntelligence #DataPreprocessing #ModelDeployment #HyperparameterTuning #FinancialRisk #Banking #PredictiveModeling #Python #DataAnalytics #ML #FinTech #CreditCard #RiskAssessment #DataCleaning #FeatureEngineering #ModelEvaluation #RealTimeInference

